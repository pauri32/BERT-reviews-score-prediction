{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Imports and Keras environment setup","metadata":{}},{"cell_type":"markdown","source":"## Import R libraries","metadata":{}},{"cell_type":"code","source":"library(magrittr)\nlibrary(dplyr)\nlibrary(rtweet)\nlibrary(textclean)\nlibrary(utf8)\nlibrary(reticulate)\nlibrary(keras)\nlibrary(tensorflow)\nlibrary(dplyr)\nlibrary(tfdatasets)\n\nlibrary(mltools)\nlibrary(data.table)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:28:12.337376Z","iopub.execute_input":"2022-01-30T19:28:12.340009Z","iopub.status.idle":"2022-01-30T19:28:12.369652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Install transformers and Keras libraries in Conda","metadata":{}},{"cell_type":"code","source":"library(reticulate)\n\nreticulate::py_install('transformers', pip = TRUE)\nreticulate::py_install('keras-bert', pip = TRUE)\n\nconfig_path = file.path(\"../input/bertconfig/bert_config.json\")\npretrained_path = file.path(\"../input/bertconfig/bert_model.ckpt\")\nvocab_path = file.path(\"../input/bertconfig/vocab.txt\")\n\nk_bert = import('keras_bert')","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:28:12.372646Z","iopub.execute_input":"2022-01-30T19:28:12.37423Z","iopub.status.idle":"2022-01-30T19:28:14.953679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load \"Amazon cell phones reviews\" dataset","metadata":{}},{"cell_type":"code","source":"df_reviews <- read.csv(\"../input/amazon-cell-phones-reviews/20191226-reviews.csv\")","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2022-01-30T19:28:14.957198Z","iopub.execute_input":"2022-01-30T19:28:14.958981Z","iopub.status.idle":"2022-01-30T19:28:15.497727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data preprocessing\n\n### Dataframe structure\n- ASIN: Identifier of the device\n- Name: Name of the Amazon's user\n- Rating: Number of stars given by the user to the product\n- Date: Date of the review\n- Verified: Indicates whether the user has been verified in the platform or not\n- Title: Title of the review\n- Body: Content of the review\n- Helpful votes: Number of users that have indicated that the review is 'helpful'","metadata":{}},{"cell_type":"code","source":"head(df_reviews, n=5)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:28:15.500936Z","iopub.execute_input":"2022-01-30T19:28:15.50263Z","iopub.status.idle":"2022-01-30T19:28:15.532228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Selection of the useful variables for the prediction and the ID of the device\nSeveral combinations of variables could have been used for this project. However, as the intention is to create a model able to predict also the score of reviews in other platforms, only the most basic ones have been chosen:\n- **ASIN**: In order to be aware of which device is being analyzed\n- **Body**: Will be used as input for the model\n- **Rating**: Is the target to predict","metadata":{}},{"cell_type":"code","source":"df_reviews <- subset(df_reviews, select = c(asin, body, rating))","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:28:15.535461Z","iopub.execute_input":"2022-01-30T19:28:15.537054Z","iopub.status.idle":"2022-01-30T19:28:15.558357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nulls cleaning for these variables.","metadata":{}},{"cell_type":"code","source":"df_reviews <- df_reviews %>% filter(!is.na(df_reviews$body)) \ndf_reviews <- df_reviews %>% filter(!is.na(df_reviews$rating)) \ndf_reviews <- df_reviews %>% filter(!is.na(df_reviews$asin))","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:28:15.561373Z","iopub.execute_input":"2022-01-30T19:28:15.563155Z","iopub.status.idle":"2022-01-30T19:28:15.583456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Rating distribution\nThe distribution of the target is analyzed using a barplot.","metadata":{}},{"cell_type":"code","source":"barplot(prop.table(table(df_reviews$rating)), col=\"blue\", main = \"Rating Distribution\")","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:28:15.586318Z","iopub.execute_input":"2022-01-30T19:28:15.587911Z","iopub.status.idle":"2022-01-30T19:28:15.653298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Undersampling reviews\nAs the distribution of the ratings is clearly non-uniform distributed, it has been decided to follow an arbitrary sampling method. In this case, as the dataset includes enough entries for each target, it has been decided not to oversample, as it could have been produced overfitting, but to undersample the dataframe to obtain the same number of inputs for each target.","metadata":{}},{"cell_type":"code","source":"nsample <- as.numeric(df_reviews %>% \n        group_by(rating) %>% \n        count() %>% \n        ungroup() %>% \n        summarise(min(n)))\n\ndf_rating1 <- df_reviews %>% filter(df_reviews$rating == 1)\ndf_rating2 <- df_reviews %>% filter(df_reviews$rating == 2)\ndf_rating3 <- df_reviews %>% filter(df_reviews$rating == 3)\ndf_rating4 <- df_reviews %>% filter(df_reviews$rating == 4)\ndf_rating5 <- df_reviews %>% filter(df_reviews$rating == 5)\n\ndf_list <- list(df_rating1[sample(nrow(df_rating1), 1.3*nsample), ],\n                df_rating2[sample(nrow(df_rating2), nsample), ],\n                df_rating3[sample(nrow(df_rating3), 1.05*nsample), ],\n                df_rating4[sample(nrow(df_rating4), 1.1*nsample), ],\n                df_rating5[sample(nrow(df_rating5), 1.5*nsample), ])\ndf_under <- Reduce(function(x, y) merge(x, y, all=TRUE), df_list, accumulate=FALSE)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:28:15.65666Z","iopub.execute_input":"2022-01-30T19:28:15.658327Z","iopub.status.idle":"2022-01-30T19:28:16.381646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(df_under)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:28:16.38485Z","iopub.execute_input":"2022-01-30T19:28:16.386543Z","iopub.status.idle":"2022-01-30T19:28:16.416919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"barplot(prop.table(table(df_under$rating)), col=\"blue\", main = \"Rating Distribution\")\ndf_reviews <- df_under","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:28:16.420197Z","iopub.execute_input":"2022-01-30T19:28:16.421975Z","iopub.status.idle":"2022-01-30T19:28:16.488118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Text cleaning\nFirst, as several emojis are included in the reviews, they have been replaced by text. With the *textclean* library, emojis are transformed in descriptions of themselfs.\n\nHowever, as some emojis have different variations (for instance, when choosing the color of the face of the symbol) they include a flag, accepted by UTF-8, but not ASCI that has to be deleted.\n\nFinally, the body of the review is UTF-8 normalized and the reviews with 1 or less characters are removed. ","metadata":{}},{"cell_type":"code","source":"df_reviews$body <- replace_non_ascii(replace_emoji(df_reviews$body), \"\")\ndf_reviews$body <- replace_emoticon(df_reviews$body)\ndf_reviews$body <- utf8_normalize(df_reviews$body)\n\ndf_reviews <- df_reviews %>% filter(nchar(body) >= 1)\nhead(df_reviews)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:28:16.491421Z","iopub.execute_input":"2022-01-30T19:28:16.493306Z","iopub.status.idle":"2022-01-30T19:29:44.724662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### One-hot encoding\nBefore enconding the rating, the column is saved of the dataframe is saved to be used as target when measuring the performance of the prediction.\n\nThen, the 5 values for the stars are hot-encoded in order to be classified.","metadata":{}},{"cell_type":"code","source":"df_reviews$target <- df_reviews$rating\n\ndf_reviews$rating <- as.factor(df_reviews$rating)\ndf_reviews <- one_hot(as.data.table(df_reviews))\n\nhead(df_reviews)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:29:44.727683Z","iopub.execute_input":"2022-01-30T19:29:44.729483Z","iopub.status.idle":"2022-01-30T19:29:44.939545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling BERT\n### Sets for evaluation\nFirst, data is splitted in a train and test set, in order to be evaluated lately.","metadata":{}},{"cell_type":"code","source":"train_index <- sample(seq_len(nrow(df_reviews)), size = floor(0.7 *  nrow(df_reviews)))\ndf_train <- df_reviews[train_index,]\ndf_test <- df_reviews[-train_index,]","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:29:44.942753Z","iopub.execute_input":"2022-01-30T19:29:44.944771Z","iopub.status.idle":"2022-01-30T19:29:44.976038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tokenization\nCreate a Tokenizer from a loaded corpus created for general NLP purposes.","metadata":{}},{"cell_type":"code","source":"library(reticulate)\n\nreticulate::py_install('transformers', pip = TRUE)\nreticulate::py_install('keras-bert', pip = TRUE)\n\nconfig_path = file.path(\"../input/bertconfig/bert_config.json\")\npretrained_path = file.path(\"../input/bertconfig/bert_model.ckpt\")\nvocab_path = file.path(\"../input/bertconfig/vocab.txt\")\n\nk_bert = import('keras_bert')","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:29:44.981489Z","iopub.execute_input":"2022-01-30T19:29:44.985953Z","iopub.status.idle":"2022-01-30T19:29:47.720667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"token_dict = k_bert$load_vocabulary(vocab_path)\ntokenizer = k_bert$Tokenizer(token_dict)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:29:47.723966Z","iopub.execute_input":"2022-01-30T19:29:47.725775Z","iopub.status.idle":"2022-01-30T19:29:47.848921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This function is used to get the input of the model. \n\nUsing the encode method of the tokenizer, the tokens and mask for each row is obtained. In this case, the values saved for the tokens are not string objects, but integers that represent them.\nMasked tokens are used to hide information to the model during the training process and make them more capable of generalizing the inputs given, and thus becoming more flexible and robust to changes.\n","metadata":{}},{"cell_type":"code","source":"get_tokens = function(df_set) {\n    c(tokens, segments, target) %<-% list(list(),list(),list())\n\n    for (i in 1:nrow(df_set)) {\n        c(tk, seg) %<-% tokenizer$encode(df_set[[\"body\"]][i], max_len=50L)\n\n        tokens = tokens %>% append(list(as.matrix(tk)))\n        segments = segments %>% append(list(as.matrix(seg)))        \n    }\n    \n    return(list(tokens, segments))\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:29:47.852064Z","iopub.execute_input":"2022-01-30T19:29:47.853812Z","iopub.status.idle":"2022-01-30T19:29:47.865096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train set\nc(tk_train, seg_train) %<-% get_tokens(df_train)\n\ntokens_train = do.call(cbind, tk_train) %>% t()\nsegments_train = do.call(cbind, seg_train) %>% t()\n#y_train = do.call(cbind, target_train) %>% t()\ny_train = data.matrix(df_train[ , 3:7])\n\nx_train = c(list(tokens_train), list(segments_train))\n\n# Test set\nc(tk_test, seg_test) %<-% get_tokens(df_test)\n\ntokens_test = do.call(cbind, tk_test) %>% t()\nsegments_test = do.call(cbind, seg_test) %>% t()\n# y_test = do.call(cbind, target_test) %>% t()\ny_test = data.matrix(df_test[ , 3:7])\n\nx_test = c(list(tokens_test), list(segments_test))","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:29:47.867891Z","iopub.execute_input":"2022-01-30T19:29:47.869497Z","iopub.status.idle":"2022-01-30T19:30:46.30478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transfer learning\nFirst, a pre-trained model is loaded. This model has not been created for any specific purpose, but to be used as a baseline for others.","metadata":{}},{"cell_type":"code","source":"model = k_bert$load_trained_model_from_checkpoint(\n  config_path,\n  pretrained_path,\n  training=TRUE,\n  trainable=TRUE)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:30:46.308042Z","iopub.execute_input":"2022-01-30T19:30:46.310118Z","iopub.status.idle":"2022-01-30T19:30:50.203113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameter-tuning\nThe input and output layers are added to the BERT model, choosing the activation function and the number of output units. Then, the decay and warmup steps are created according to the length of the training dataset, the batch size and the number of epochs.","metadata":{}},{"cell_type":"code","source":"c(decay_steps, warmup_steps) %<-% k_bert$calc_train_steps(\n  y_train %>% length(),\n  batch_size=70,\n  epochs=1\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:30:50.206688Z","iopub.execute_input":"2022-01-30T19:30:50.208874Z","iopub.status.idle":"2022-01-30T19:30:50.235302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_token = get_layer(model,name = 'Input-Token')$input\ninput_segment = get_layer(model,name = 'Input-Segment')$input\ninput_layers = list(input_token,input_segment)\n\ndense = get_layer(model,name = 'NSP-Dense')$output\n\noutputs = dense %>% layer_dense(units=5L, activation='softmax',\n                         kernel_initializer=initializer_truncated_normal(stddev = 0.02),\n                         name = 'output')\n\nmodel = keras_model(inputs = input_layers,outputs = outputs)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:30:50.241909Z","iopub.execute_input":"2022-01-30T19:30:50.243322Z","iopub.status.idle":"2022-01-30T19:30:50.389323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model %>% compile(\n  k_bert$AdamWarmup(decay_steps=decay_steps, \n                    warmup_steps=warmup_steps, lr=1e-4),\n  loss = \"categorical_crossentropy\",\n  metrics = \"categorical_accuracy\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:30:50.396217Z","iopub.execute_input":"2022-01-30T19:30:50.401149Z","iopub.status.idle":"2022-01-30T19:30:50.440343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model fitting","metadata":{}},{"cell_type":"code","source":"model %>% fit(\n    x=x_train,\n    y=y_train,\n    epochs=3,\n    batch_size=70,\n    validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:30:50.445929Z","iopub.execute_input":"2022-01-30T19:30:50.450187Z","iopub.status.idle":"2022-01-30T19:38:56.125412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions and evaluation\n### Predicting values from the Test Set","metadata":{}},{"cell_type":"code","source":"predicted_values = model$predict(x_test)\n\ny_predicted <- vector()\nfor(i in 1:length(predicted_values[,1])){\n    y_predicted[i] = which.max(predicted_values[i, ])\n}\ny_target <- as.vector(df_test[[\"target\"]])","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:38:56.128861Z","iopub.execute_input":"2022-01-30T19:38:56.130674Z","iopub.status.idle":"2022-01-30T19:39:14.370881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction vs Target comparison for the 10 first values.","metadata":{}},{"cell_type":"code","source":"for(i in 1:10){\n    print(paste0(\"-prediction = \", y_predicted[i]))\n    print(paste0(\"-target = \", y_target[i]))\n    print(\"---------------------------\")\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:39:45.828968Z","iopub.execute_input":"2022-01-30T19:39:45.830535Z","iopub.status.idle":"2022-01-30T19:39:45.85266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(table(y_predicted))\nprint(table(y_target))","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:39:52.285929Z","iopub.execute_input":"2022-01-30T19:39:52.287389Z","iopub.status.idle":"2022-01-30T19:39:52.307925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion matrix","metadata":{}},{"cell_type":"code","source":"library(caret)\n\ncfm = caret::confusionMatrix(as.factor(y_predicted), as.factor(y_target))\nprint(cfm)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:39:56.945759Z","iopub.execute_input":"2022-01-30T19:39:56.947244Z","iopub.status.idle":"2022-01-30T19:39:56.979499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfm$accuracy","metadata":{"execution":{"iopub.status.busy":"2022-01-30T19:39:14.455784Z","iopub.execute_input":"2022-01-30T19:39:14.457447Z","iopub.status.idle":"2022-01-30T19:39:14.471372Z"},"trusted":true},"execution_count":null,"outputs":[]}]}